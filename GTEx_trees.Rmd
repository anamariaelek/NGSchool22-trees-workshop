---
title: "Tree Based Methods Workshop"
author: "Anamaria Elek"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    df_print: paged
    toc: true
    toc_float: true
    toc_depth: 2
---

In this workshop we are going to use tree-based methods to construct Gene Regulatory Networks (GRNs).

## Introduction

The expression of each gene is regulated by a set of transcription factors (TFs). If a level of TF expression is changed (e.g. a TF is knocked-down), the expression level of it's downstream target genes will be afffected. We can therfore build a model that predicts expression of a particular gene based on the expression of it's potential regulators. Then, by grouping TFs and their targets based on this coordinated co-expression, we can obtain simple Gene Regulatory Networks (GRNs).

Tree based methods are particularly suitable for this problem because:
 * they make essentially no assumptions about the nature of the relationships between TF and gene expression (which can be non-linear), 
 * they can potentially capture high-order conditional dependencies between expression patterns,
 * they can handle more samples than features,
 * their interpretability allows direct selection of important TFs.
 
## Setup

```{r setup,  message=FALSE, warning=FALSE}
library(data.table)
library(stringr)
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
library(ipred)
library(ranger)
library(party)
```

## Data

GTEx portal contains gene expression data for various human tissues, you can access the data [here](https://www.gtexportal.org/home/datasets#filesetFilesDiv131).  

We will use transcript-per-million (TPM) normalized gene counts. This normalization accounts for different sequencing depths in different samples (i.e. features are on the same scale and comparable between samples). TPM is, however, biased by gene length (i.e. longer genes are going to have more TPMs than a shorter gene expressed at the same level). Think about this problem, how we should deal with it?
  
We will work with 578 lung samples. You can download the data directly from GTEx (it should not take long), or load the local copy.

```{r eval=FALSE}
# download data from GTEx portal
url <- "https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/gene_reads/gene_reads_2017-06-05_v8_lung.gct.gz"
dt <- fread(url)
```

```{r}
# load local copy of data
dt <- fread("data/gene_tpm_2017-06-05_v8_lung.gct.gz")
```

```{r}
# dimensions
dim(dt)
dt[1:10,1:10]
```

There are 56,200 genes from 578 lung samples in our data.  
Since we will only use TFs as variabes in our model, we will include additional column to specify if the gene is a TF or not. You can download a list of 1639 human TFs from the curated database [here](http://humantfs.ccbr.utoronto.ca/download.php), or again, load a local copy of this data.

```{r eval=FALSE}
# download TF data
url <- "http://humantfs.ccbr.utoronto.ca/download/v_1.01/TFs_Ensembl_v_1.01.txt"
tfs <- readLines(url)
```
```{r}
# load local copy of TF data
tfs <- readLines("data/TFs_Ensembl_v_1.01.txt")
head(tfs)
length(tfs)

# strip transcript ID from GTEx data
dt[, Name := str_remove(Name, "\\.\\d+$")]

# add TF info
dt[,TF := ifelse(Name %in% tfs, TRUE, FALSE)]

# most of TFs are present in our GTEx data.
dt[, .N, TF]

# we will use more informative gene names instead of ensembl IDs
dt[,Description:=str_replace(Description,"-","_")] # - causes formula to break
tfs <- dt[TF == TRUE, Description]
```

Let's do some exploratory data analysis.

```{r}
# extract only TPM values
tpm <- dt[,-c(1:4)]
# transpose to have observations in rows and features in columns
tpm <- as.data.frame(t(tpm))
colnames(tpm) <- dt$Description
quants <- t(apply(tpm, 1, quantile))
head(quants)
```

We can remove genes that are not expressed in any sample.

```{r warning=FALSE, message=FALSE, fig.height=6, fig.width=8}
# remove genes not expressed in any sample
not_expressed <- which(colSums(tpm) == 0)
length(not_expressed)
tpm <- tpm[, -not_expressed]
quants <- t(apply(tpm, 1, quantile))
head(quants)
```

Log transform the data and remove genes that are very lowly expressed in most of the samples.

```{r}
# log transform
tpm <- log(tpm+1)
quants <- t(apply(tpm, 1, quantile))
head(quants)

# remove lowly expressed genes
hist(colSums(tpm), breaks = 50); abline(v=100, col="red")
low_expressed <- which(colSums(tpm) < 100)
sum(names(low_expressed) %in% tfs)
tpm <- tpm[, -low_expressed]

# how many TFs (i.e. variables) we have left?
tfs <- tfs[tfs %in% colnames(tpm)]
length(tfs)

```
```{r include=FALSE, eval=FALSE}
# TPM distribution for TFs vs non-TFs
dtm <- reshape2::melt(tpm, value.name = "TPM")
dtm$TF <- ifelse(dtm$variable %in% tfs, TRUE, FALSE)
gp <- ggplot(dtm, aes(TPM, fill=TF)) + 
  geom_histogram(bins=100) + 
  scale_x_log10() +
  scale_fill_viridis_d() +
  facet_grid(TF~., scales = "free_y", labeller = label_both) +
  theme(legend.position = "none") 
gp
```

**Note**: A more sophisticated feature selection methods are available, they will be covered in tomorrow's lectures.  

Split the data into train and test samples.

```{r}
set.seed(1950)
tpm_train_id <- sample(1:nrow(tpm), size = 0.9 * nrow(tpm))
tpm_train <- tpm[tpm_train_id, ]; nrow(tpm_train)
tpm_test  <- tpm[-tpm_train_id, ]; nrow(tpm_test)
```

First we will fit different regression trees to predict individual genes expression. Start with one of the following example genes for which there are pre-calculated grid search results files:  

* SFTPA1 - a member of SFTP gene family encoding lung surfactant proteins 
* EPAS1 - a type of hypoxia-inducible factor, TFs involved in the induction of genes regulated by oxygen (it is induced as oxygen levels fall)
* NKX2_1

Same approach can then be applied to all other genes.

```{r}
# outcome variable
gene <- "NKX2_1"

# predictor variables
tfs <- setdiff(tfs, gene)
```

***

## Regression Tree Model

Use `rpart::tree()` function to fit decision tree model.

```{r fig.height=5, fig.width=8}
require(rpart)

set.seed(1950)

# build tree
tpm_tree <- rpart(
  formula = as.formula(paste(gene, "~ .", collapse = " ")),
  data = tpm_train[,c(gene,tfs)],
  method = "anova" # for regression
)

# plot tree
require(rpart.plot)
rpart.plot(tpm_tree)
```

The tree is showing the percentage of data that fall to each node, and the average TPM for corresponding branch

`rpart` automatically performs a 10-fold cross validation for a range of cost complexity $\alpha$ values (`cp` parameter passed to `rpart.control`) to prune the tree. We can look at the reduction in cross-validation error with increased number of splits.

```{r fig.height=4, fig.width=6}
plotcp(tpm_tree)
```

**Note**: This CV error is equivalent to predicted residual error sum of squares (PRESS); it is not equivalent to the root mean squared error (RMSE) which we will calculate later.

```{r}
# get stats for different cp values
tpm_tree$cptable
```

In addition to the cost complexity `cp`, other `rpart` parameters we can tune are:  

* `minsplit`, the minimum number of data points required to attempt a split before it is forced to create a terminal node (default is 20)  
* `maxdepth`, the maximum number of internal nodes between the root node and the terminal nodes (default is 30).  

In order to automatically tune these parameters, we create a grid search and iterate through it. 

```{r message=FALSE, eval=TRUE}
hyper_grid <- expand.grid(
  minsplit = seq(20, 40, 1),
  maxdepth = seq(20, 40, 1)
)
 # 
nrow(hyper_grid)

# loop over grid search
set.seed(1950)
tpm_list <- lapply(1:nrow(hyper_grid), function(i) {
  
  # train a model 
  tpm_tree <- rpart(
    formula = as.formula(paste(gene, "~ .", collapse = " ")),
    data = tpm_train[, c(gene,tfs)],
    method  = "anova",
    control = list(
      minsplit = hyper_grid$minsplit[i], 
      maxdepth = hyper_grid$maxdepth[i]
    )
  )
  
  # get error
  tpm_tree$cptable[which.min(tpm_tree$cptable[,"xerror"]),]

  })

# merge results
tpm_cp <- do.call('rbind', tpm_list)

# add results to grid
hyper_grid <- cbind(hyper_grid, tpm_cp)

# save
fwrite(hyper_grid, file = sprintf("data/hypergrid.tree.%s.csv",gene))
```

After building all the models, we select the one with lowest CV error.

```{r fig.height=6, fig.width=6}
hyper_grid <- fread(sprintf("data/hypergrid.tree.%s.csv",gene))
head(hyper_grid[order(xerror)])

# plot grid search results
ggplot(hyper_grid, aes(minsplit, maxdepth, fill = xerror)) + 
  geom_tile() + coord_fixed() + scale_fill_viridis_c(direction = -1)
```

Notice that the error for top model is lower than for the first tree built with the default parameters.  

Finally, use the best parameters to build the final model.

```{r fig.height=5, fig.width=8}
# build the model using best parameters from grid search
i <- which.min(hyper_grid$xerror)
tpm_best_tree <- rpart(
  formula = as.formula(paste(gene, "~ .", collapse = " ")),
  data = tpm_train[, c(gene,tfs)],
  method  = "anova",
  control = list(
    minsplit = hyper_grid$minsplit[i],
    maxdepth = hyper_grid$maxdepth[i],
    cp = hyper_grid$CP[i]
  )
)

# plot tree
rpart.plot(tpm_tree)
```

Use this model for prediction with test data.

```{r fig.width=6, fig.height=6}
pred <- predict(tpm_best_tree, newdata = tpm_test[, tfs])
RMSE(pred = pred, obs = tpm_test[, gene])

pred_df <- data.frame(predicted=pred, actual=tpm_test[, gene])
ggplot(pred_df, aes(predicted, actual)) + 
  geom_point() + 
  geom_smooth(method='lm', formula=y~x)
```

## Bagging

The major parameter for bagging is the number of trees to average (`nbagg`, default is 25). Increasing this value results in lower error, but after the initial drop, it soon becomes stable.   

### `ipred`

We can train a regression tree with bagging similarly to training a single tree, using `ipred::bagging` function. We will build models with different number of averaged trees, and retrieve out-of-the-bag OOB error for each (`ipred` does not perform CV)   

```{r message=FALSE, eval=TRUE}
require(ipred)

set.seed(1950)

# get OOB errors for models with range of bagged trees
nbagg <- seq(10, 200, 2)

rmse <- sapply(nbagg, function(i) {
  bt <- bagging(
    formula = as.formula(paste(gene, "~ .", collapse = " ")),
    data = tpm_train[,c(gene,tfs)],
    coob = TRUE,
    nbagg = i
  )
  bt$err
})

rmse_df <- data.frame(nbagg, rmse)
fwrite(rmse_df, file = sprintf("data/hypergrid.bagging.%s.csv",gene))
```

We can build a model using best parameter from grid search.

```{r}
# load precalculated values
rmse_df <- fread(sprintf("data/hypergrid.bagging.%s.csv",gene))
ggplot(rmse_df, aes(nbagg, rmse)) + 
  geom_line() + 
  geom_vline(xintercept = 25, col = "red")

# fit model using these parameters
ntree <- rmse_df[which.min(rmse_df$rmse),]$nbagg
bagging_tree <- bagging(
  formula = as.formula(paste(gene, "~ .", collapse = " ")),
  data = tpm_train[,c(gene,tfs)],
  coob = TRUE,
  nbagg = ntree
)
```

We can use bagging model for prediction with test data.

```{r fig.width=6, fig.height=6}
pred <- predict(bagging_tree, newdata = tpm_test[, tfs])
RMSE(pred = pred, obs = tpm_test[, gene])

pred_df <- data.frame(predicted=pred, actual=tpm_test[, gene])
ggplot(pred_df, aes(predicted, actual)) + 
  geom_point() + 
  geom_smooth(method='lm', formula=y~x)
```

Notice that this is only a slight improvement over simple regression tree.

### `caret`

Alternatively, we can use `caret::train()` function which can fit a variety of different models (238, to be precise, see info [here](https://topepo.github.io/caret/available-models.html)), including bagging trees (see `names(getModelInfo())`). It's advantages are that it can automatically perform cross-validation and calculate variable importance.  

```{r}
require(caret)

# set up a 10-fold cross validation
ctrl <- trainControl(method = "cv",  number = 10) 

# CV bagged model
bagging_tree <- caret::train(
  x = tpm_train[,tfs],
  y = tpm_train[,gene],
  method = "treebag",
  num.trees = ntree,
  trControl = ctrl,
  importance = TRUE
)
```

**Note**: We could in theory use the same formula syntax as with `pred`, however, `ipred` has a problem with formula parsing of some of the column names, so we specify `x` and `y` values directly)

```{r fig.height=6, fig.width=4}
# assess results
bagging_tree

# plot most important variables
plot(varImp(bagging_tree), 30)  
```

## Random Forest

We can use `caret::train()` with fast `ranger` implementation of Random Forest, to train the model and do cross validation on the fly.

There are several parameters to tune for Random Forest:

* `mtry`, number of randomly selected variables; recommended default values are p/3 for regression problems and sqrt(p) for classification problems, where p is total number of variables
* `sample.fraction`, faction of observations to sample (default is 1)
* `min.node.size`, minimal node size (default is 5 for regression)

We will again construct the parameter grid to iterate over. We can pass it to `caret::train()` directly.

```{r eval=TRUE}
# set up a 3-fold cross validation
ctrl <- trainControl(method = "cv",  number = 3) 

# parameter grid search
hyper_grid <- expand.grid(
  splitrule = "variance", # has to be included even if not changing it
  mtry = seq(1050, 1250, by = 50),
  min.node.size = seq(5, 12, by = 1)
)

# total number of combinations
nrow(hyper_grid)

# build models without CV or importance calculation
rf_tree <- caret::train(
  x = tpm_train[,tfs],
  y = tpm_train[,gene],
  method = "ranger",
  trControl = ctrl,
  tuneGrid = hyper_grid,
  num.trees =  300, 
  importance = "none"
)

# save
grid_res <- rf_tree$results
fwrite(grid_res, file = sprintf("data/hypergrid.rf.%s.csv",gene))
```

Visualize results of grid search.

```{r fig.height=6, fig.width=5}
# load grid search results
grid_res <- fread(sprintf("data/hypergrid.rf.%s.csv",gene))

# plot
ggplot(grid_res, aes(min.node.size, mtry, fill = RMSE)) + 
  geom_tile() + scale_fill_viridis_c(direction = -1)

# top parameter combinations
grid_res[order(RMSE)][1:5]
```

Select best parameters obtained from grid search and build the model.

```{r}
require(caret)

# set up a 10-fold cross validation
ctrl <- trainControl(method = "cv",  number = 10) 

# parameter grid with fixed best values
i <- which.min(grid_res$RMSE)
tuned_grid <- expand.grid(
  splitrule = "variance", 
  mtry = grid_res$mtry[i],
  min.node.size = grid_res$min.node.size[i]
)

# CV rf model with importance calculation
rf_tree <- caret::train(
  x = tpm_train[,tfs],
  y = tpm_train[,gene],
  method = "ranger",
  trControl = ctrl,
  tuneGrid = tuned_grid,
  num.trees = 300, 
  importance = "permutation"
)

# assess results
rf_tree
```

Extract variable importance for model.

```{r fig.height=6, fig.width=4}
# plot most important variables
varimp <- varImp(rf_tree)
plot(varimp, 30)  
as.data.table(varimp$importance, keep.rownames = "Variable")[order(-Overall)]

# roc
rocimp <- filterVarImp(x = tpm_train[,tfs], y = tpm_train[,gene])
rocimp <- as.data.table(rocimp, keep.rownames = "Variable") 
rocimp[order(-Overall)]
```

Use Random Forest model for prediction with test data.

```{r fig.width=6, fig.height=6}
pred <- predict(rf_tree, tpm_test[, tfs])
RMSE(pred = pred, obs = tpm_test[, gene])

pred_df <- data.frame(predicted=pred, actual=tpm_test[, gene])
ggplot(pred_df, aes(predicted, actual)) + 
    geom_point() + 
    geom_smooth(method='lm', formula=y~x) 
```

## Conditional Trees

In all the models so far, trees were built by selecting for each split in the tree the variable that maximizes an information measure (e.g. Gini coefficient or ). This approach is inherently biased towards selecting variables with many splits, or many missing values. To tackle this, a different approach of building conditional trees uses instead significance test procedure to select variables instead. Significance is calculated for each covariate by permutations, and the one with the lowest p value is selected for split.

We will again construct the parameter grid to iterate over. We can pass it to `caret::train()` directly.

```{r eval=TRUE}
# set up a 3-fold cross validation
ctrl <- trainControl(method = "cv",  number = 3) 

# parameter grid search
hyper_grid <- expand.grid(
  mtry = seq(1050, 1250, by = 50)
)

# total number of combinations
nrow(hyper_grid)

# build models without CV or importance calculation
crf_tree <- caret::train(
  x = tpm_train[,tfs],
  y = tpm_train[,gene],
  method = "cforest",
  trControl = ctrl,
  tuneGrid = hyper_grid
)

# save
grid_res <- crf_tree$results
fwrite(grid_res, file = sprintf("data/hypergrid.crf.%s.csv",gene))
```

Visualize results of grid search.

```{r fig.height=6, fig.width=5}
# load grid search results
grid_res <- fread(sprintf("data/hypergrid.rf.%s.csv",gene))

# plot
ggplot(grid_res, aes(min.node.size, mtry, fill = RMSE)) + 
  geom_tile() + scale_fill_viridis_c(direction = -1)

# top parameter combinations
grid_res[order(RMSE)][1:5]
```

Select best parameters obtained from grid search and build the model.

```{r}
require(caret)

# set up a 10-fold cross validation
ctrl <- trainControl(method = "cv",  number = 10) 

# parameter grid with fixed best values
i <- which.min(grid_res$RMSE)
tuned_grid <- expand.grid(
  mtry = grid_res$mtry[i]
)

# CV rf model with importance calculation
crf_tree <- caret::train(
  x = tpm_train[,tfs],
  y = tpm_train[,gene],
  method = "cforest",
  trControl = ctrl,
  tuneGrid = tuned_grid
)

# assess results
crf_tree
```

Extract variable importance for model.

```{r fig.height=6, fig.width=4}
# plot most important variables
varimp <- varImp(rf_tree)
plot(varimp, 30)  
varimp_dt <- as.data.table(varimp$importance, keep.rownames = "Variable")[order(-Overall)]
head(varimp_dt)[[1]]

# roc
rocimp <- filterVarImp(x = tpm_train[,tfs], y = tpm_train[,gene])
rocimp_dt <- as.data.table(rocimp, keep.rownames = "Variable")[order(-Overall)]
head(rocimp_dt)
```

Prediction using Random Forest with conditional trees.

```{r fig.width=6, fig.height=6}
pred <- predict(crf_tree, tpm_test[, tfs])
RMSE(pred = pred, obs = tpm_test[, gene])

pred_df <- data.frame(predicted=pred, actual=tpm_test[, gene])
ggplot(pred_df, aes(predicted, actual)) + 
    geom_point() + 
    geom_smooth(method='lm', formula=y~x) 
```

## Downstream analysis

Using the variable importance, we can build a network of regulators for our gene. The choice of how many TFs include in the netwok is a bit arbitrary at this point.

```{r}

```

We can load pre-calculated model errors for different genes and order them by increasing RF RMSE.

```{r eval=TRUE}
dt = fread("data/genes.txt")
setnames(dt, c("genes","model","rmse"))
dt[,genes:=factor(genes, levels=unique(dt[model=="random_forest"][order(rmse)]$genes))]
setorder(dt,genes,rmse)
```

Random Forrest systematically outperforms single Decision Tree.

```{r eval=TRUE, fig.width=6, fig.height=4}
ggplot(dt[1:100], aes(genes, rmse, color=model)) +
  geom_line(aes(group=model)) +
  geom_point() +
  theme(
    axis.text.x = element_blank(), 
    panel.grid.major.x = element_blank(), 
    axis.ticks.length.x = unit(0,"mm"))
```

